Metadata-Version: 2.4
Name: catattack
Version: 0.1.0
Summary: CatAttack: Query-Agnostic Adversarial Triggers for Reasoning Models
Author: Meghana Rajeev, Rajkumar Ramamurthy, Prapti Trivedi, Vikas Yadav, Oluwanifemi Bamgbose, Sathwik Tejaswi Madhusudan, James Zou, Nazneen Rajani
License: MIT
Project-URL: Homepage, https://github.com/collinear-ai/CatAttack
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: jinja2
Requires-Dist: datasets
Requires-Dist: python-dotenv
Requires-Dist: requests
Requires-Dist: tqdm
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Dynamic: license-file

# CatAttack

[![arXiv](https://img.shields.io/badge/arXiv-2503.01781-b31b1b.svg)](https://arxiv.org/abs/2503.01781)

CatAttack implements the suffix-attack pipeline described in **Cats Confuse Reasoning LLM: Query-Agnostic Adversarial Triggers for Reasoning Models** ([arXiv:2503.01781](https://arxiv.org/abs/2503.01781)). The codebase is organised around three key entry points:

1. `python -m catattack.cli.main` – full pipeline driver with CLI flags.
2. `python -m catattack.cli.suffix_pipeline` – iteratively generate suffixes with the attacker + proxy loop.
3. `python -m catattack.cli.suffix_evaluator` – evaluate suffix lists on the target model and print the full metric suite.

---

## 1. Install & Configure

```bash
git clone https://github.com/collinear-ai/CatAttack.git
cd CatAttack
pip install -r requirements.txt
```

Set the environment variables expected in `config.yaml` (e.g. `OPENAI_API_KEY`, `FIREWORKS_API_KEY`). You can copy `.env.example` and run `source .env` before executing scripts.

If you plan to push evaluation results or modified problems to Hugging Face, make sure to replace `{{test_dataset_name}}`, `{{modified_problems_hf_hub}}`, and `{{evaluation_hf_hub}}` in `config.yaml` with the appropriate dataset IDs.

The main configuration file is `config.yaml`. Key sections:

```
models:
  attacker:
    provider: "openai"
    model: "gpt-4o"
    api_key_env: "OPENAI_API_KEY"
  proxy_target:
    provider: "openai"
    model: "accounts/fireworks/models/deepseek-v3"
    base_url: "https://api.fireworks.ai/inference/v1"
    api_key_env: "FIREWORKS_API_KEY"
  target_model:
    provider: "openai"
    model: "gpt-4o"
    api_key_env: "OPENAI_API_KEY"
  judge:
    provider: "openai"
    model: "gpt-4o"
    api_key_env: "OPENAI_API_KEY"

dataset:
  name: "AI-MO/NuminaMath-CoT"  # HuggingFace dataset name
  split: "test"
  num_problems: 2
  # Optional: Leave name and local_path empty to use hardcoded sample problems

# Evaluation dataset (used by catattack.suffix_evaluator)
test_dataset:
  name: "{{test_dataset_name}}"
  split: "train"
  num_problems: 5

attack:
  max_iterations: 10
  num_threads: 2

output:
  results_dir: "results"
  push_to_hub: false
  hub_dataset_name: "{{modified_problems_hf_hub}}"
  hub_private: true
  include_failed_attacks: true

evaluation:
  model_key: "target_model"
  num_runs: 6
  num_problems: 10
  push_to_hub: false
  hub_dataset_name: "{{evaluation_hf_hub}}"
  hub_private: true
```

### Dataset Configuration Options

The `dataset` section supports three modes:

1. **HuggingFace Dataset** (recommended):
   ```yaml
   dataset:
     name: "AI-MO/NuminaMath-CoT"
     split: "train"
     num_problems: 100
     problem_field: "problem"
     answer_field: "solution"
   ```

2. **Local Dataset File**:
   ```yaml
   dataset:
     local_path: "./my_problems.json"
     num_problems: 50
     problem_field: "question"
     answer_field: "answer"
   ```
   Supports `.json`, `.jsonl`, and `.csv` formats.

3. **Hardcoded Sample Problems** (for quick testing):
   ```yaml
   dataset:
     num_problems: 10  # Leave name and local_path empty
   ```
   Uses 10 hardcoded math problems as fallback. Perfect for testing without downloading datasets.

---

## References

```
@misc{rajeev2025catsconfusereasoningllm,
      title={Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models}, 
      author={Meghana Rajeev and Rajkumar Ramamurthy and Prapti Trivedi and Vikas Yadav and Oluwanifemi Bamgbose and Sathwik Tejaswi Madhusudan and James Zou and Nazneen Rajani},
      year={2025},
      eprint={2503.01781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.01781}, 
}
```

```bash
pip install -e .
```

After installing, you can run the packaged entry points from anywhere:

- `python -m catattack.cli.main` – full CLI driver.
- `python -m catattack.cli.suffix_pipeline` – suffix generation loop.
- `python -m catattack.suffix_evaluator` – evaluate suffix lists.
